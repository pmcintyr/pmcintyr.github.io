{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90797d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given rows with the same street name, house numbers should be in increasing order\n",
    "def replace_non_increasing(street_group):\n",
    "    increasing_value = None\n",
    "    for i in range(len(street_group)):\n",
    "        if increasing_value is None or street_group.iloc[i]['no_maison'] > increasing_value:\n",
    "            increasing_value = street_group.iloc[i]['no_maison']\n",
    "        else:\n",
    "            # When house numbers decrease, set them to the last increasing house number\n",
    "            street_group.at[street_group.index[i], 'no_maison'] = increasing_value\n",
    "    return street_group\n",
    "\n",
    "def house_number_clean(input_file):\n",
    "    \n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(input_file)\n",
    "    \n",
    "    # Find the total number of rows\n",
    "    total_rows = len(df)\n",
    "    \n",
    "    ### NON-NUMERIC HOUSE NUMBER CLEANING\n",
    "\n",
    "    # Find the number of non-numeric values in the no_maison column before processing\n",
    "    non_numeric_rows_before_processing = df['no_maison'].apply(lambda x: not str(x).isnumeric()).sum()\n",
    "\n",
    "    # Replace all non-numeric values with the previous numeric value above, else set value to NaN\n",
    "    df['no_maison'] = pd.to_numeric(df['no_maison'], errors='coerce')\n",
    "    \n",
    "    # Replace NaN and \"·\" values with the value above it in the no_maison column\n",
    "    df['no_maison'].fillna(method='ffill', inplace=True)\n",
    "    df['no_maison'].replace('·', method='ffill', inplace=True)\n",
    "    \n",
    "    ### NON-INCREASING HOUSE NUMBER CLEANING\n",
    "    \n",
    "    # Find the number of rows with non-increasing values for the same street name before processing\n",
    "    non_increasing_rows_before_processing = df.groupby('nom_rue')['no_maison'].diff().lt(0).sum()\n",
    "\n",
    "    # Invalid house number prefix and suffix handler\n",
    "    # Invalid prefix example: (12,13,114) instead of (12,13,14) => 114 % 100 = 14\n",
    "    # Invalid suffix example: (12,13,140) instead of (12,13,14) => 140 // 10 = 14\n",
    "    last_street_name = None\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.isnull(row['no_maison']):\n",
    "            if(index == 0):\n",
    "                df.at[index, 'no_maison'] = 1\n",
    "            else:\n",
    "                df.at[index, 'no_maison'] = df.at[index - 1, 'no_maison']\n",
    "\n",
    "        if row['no_maison'] > 100:\n",
    "            if(index !=0):\n",
    "                if (df.at[index, 'no_maison'] // 10 >= df.at[index - 1, 'no_maison']):\n",
    "                    df.at[index, 'no_maison'] = df.at[index, 'no_maison'] // 10 # handles most 1-digit suffixes\n",
    "                elif(df.at[index, 'no_maison'] % 100 >= df.at[index - 1, 'no_maison']):\n",
    "                    df.at[index, 'no_maison'] = row['no_maison'] % 100 #handles most 1-digit prefixes\n",
    "                else:\n",
    "                    df.at[index, 'no_maison'] = df.at[index - 1, 'no_maison'] #handles all other prefixes and suffixes\n",
    "\n",
    "    # Find the number of non-numeric values in the no_maison column after processing\n",
    "    non_numeric_rows = df['no_maison'].isnull().sum()\n",
    "    \n",
    "    # Remove all remaining non-increasing house numbers per street\n",
    "    df = df.groupby('nom_rue').apply(replace_non_increasing).reset_index(drop=True)\n",
    "            \n",
    "    # Find the number of rows with non-increasing values in the no_maison column for the same street name\n",
    "    non_increasing_rows = (df.groupby('nom_rue')['no_maison'].diff() < 0).sum() if 'no_maison' in df else 0\n",
    "\n",
    "    # print(f\"For {input_file} with {total_rows} rows: before processing we had {non_numeric_rows_before_processing} non-numeric values and {non_increasing_rows_before_processing} non-increasing values on the same street, after processing we get {non_numeric_rows} non-numeric values, {non_increasing_rows} non-increasing values on the same street, {non_increasing_rows/total_rows*100:.1f}% bad house numbers remain.\")\n",
    "\n",
    "    # Save the resulting Excel file\n",
    "    output_file = input_file.replace('.xlsx', '_filtered_numbers.xlsx')\n",
    "    output_file = output_file.replace('./recensements','./recensements_cleaned')\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "# Example function usage\n",
    "# input_file = './recensements/1832.xlsx'\n",
    "# house_number_clean(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb09666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning files\n",
      "1 out of 23 files cleaned\n",
      "2 out of 23 files cleaned\n",
      "3 out of 23 files cleaned\n",
      "4 out of 23 files cleaned\n",
      "5 out of 23 files cleaned\n",
      "6 out of 23 files cleaned\n",
      "7 out of 23 files cleaned\n",
      "8 out of 23 files cleaned\n",
      "9 out of 23 files cleaned\n",
      "10 out of 23 files cleaned\n",
      "11 out of 23 files cleaned\n",
      "12 out of 23 files cleaned\n",
      "13 out of 23 files cleaned\n",
      "14 out of 23 files cleaned\n",
      "15 out of 23 files cleaned\n",
      "16 out of 23 files cleaned\n",
      "17 out of 23 files cleaned\n",
      "18 out of 23 files cleaned\n",
      "19 out of 23 files cleaned\n",
      "20 out of 23 files cleaned\n",
      "21 out of 23 files cleaned\n",
      "22 out of 23 files cleaned\n",
      "23 out of 23 files cleaned\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "value_counts = {}\n",
    "folder_path = './recensements'\n",
    "clean_folder_path = './recensements_cleaned'\n",
    "file_list = [filename for filename in os.listdir(folder_path) if filename.endswith(\".xlsx\")]\n",
    "number_of_files = len(file_list)\n",
    "\n",
    "# Make sure rows have increasing house numbers in all excel files\n",
    "print(\"cleaning files\")\n",
    "#remove_folder(clean_folder_path)\n",
    "for i, filename in enumerate(file_list,start=1):\n",
    "    print(f\"{i} out of {number_of_files} files cleaned\")\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    house_number_clean(file_path)\n",
    "\n",
    "# Iterate through each file in the folder\n",
    "for filename in os.listdir(clean_folder_path):\n",
    "        file_path = os.path.join(clean_folder_path, filename)\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Get the second column\n",
    "        column_values = df.iloc[:, 1]\n",
    "        # Count the occurrences of each value in the second column\n",
    "        for value in column_values:\n",
    "            if value in value_counts:\n",
    "                value_counts[value] += 1\n",
    "            else:\n",
    "                value_counts[value] = 1\n",
    "\n",
    "# Convert the dictionary to a pandas DataFrame\n",
    "result_df = pd.DataFrame(list(value_counts.items()), columns=['Value', 'Count'])\n",
    "\n",
    "# Sort the DataFrame by the 'Count' column in descending order\n",
    "result_df = result_df.sort_values('Count', ascending=False)\n",
    "\n",
    "# Values to filter out\n",
    "values_to_filter = [\"pre\",\"martherey\",\"st jean\",\"laurent\",\"de bourg\",\"francois\",\"annee de naissance\",\"pierre\",\"rue du pont\",\"chauerau\",\"chailly\",\"marteray\",\"fre\",\"halle\",\"jn francois\",\"derriere\",\"id id\",\"laurens\",\"grand s jean\",\"grand jean\",\"devant\",\"cheneau\",\"cile de vant\",\"st laurens\",\"et\",\"cile derriere\",\"du marche\",\"patud\",\"francoise\",\"gd st jean\",\"hallede st laurent\",\"haurent\",\"grand fs jean\",\"st laur\",\"d halle\",\"walle\",\"jn jean\",\"grand\",\"paud\",\"frand chene\",\"cite derrier\",\"moulins de pepinet\",\"rue de martheray\",\"cheneau bourg\",\"marthony\",\"marthorey\",\"jennes\",\"grand f jean\",\"salud\",\"de francois\",\"du sont\",\"cuchy\",\"sejan\",\"le pont\",\"duz re\",\"montee de st laurent\",\"marthe\",\"chemin de bourg\",\"place du pont\",\"marthery\",\"f pierre\",\"martherey e\",\"dre\",\"de pierre\",\"la barre\",\"grand fr jean\",\"d etienne\",\"valud\",\"st fran\",\"chavanne\",\"ft pierre\",\"grand sn jean\",\"aisse\",\"cite devriere\",\"id .\",\"luite dri\",\"no de leur recepisse\",\"cile derrier\",\"flaurent\",\"della barre\",\"mererie\",\"halle de laurent\",\"du re\",\"chaucrau .\",\"l walle\",\"marthere\",\"theneau de bourg\",\"e aisse\",\"rue de francois\",\"cete derriere\",\"no des\",\"pennes\",\"marthoray\",\"etienne\",\"marberay\",\"st laurant\",\"cite derric\",\"ctraz\",\"chaucraie\",\"bourge\",\"ste pierre\",\"theneau bourg\",\"halle de s laurt\",\"slaurent\",\"petit gjean\",\"montee de st monte\",\"lite de vans\",\"l hopital\",\"rue du pre\",\"de mercerie\",\"pont\",\"monorier\",\"nerie\",\"no es\",\"monte st laurent\",\"uve\",\"grangeneuve\",\"sdu\",\"dean\",\"ler\",\"luchy\",\"de st laurent\",\"no de\",\"grand sjean\",\"tre\",\"cite dessons\",\"monbe clauron\",\"rapaz\",\"pre du marche\",\"sallaz\",\"grotte\",\"monblesson\",\"halle f laurent so\",\"veuf\",\"marherey\",\"chaueran\",\"st martin\",\"martberty\",\"challes st laurens\",\"chaz\",\"boston\",\"plaurent\",\"de marthenay\",\"cite ederriere\",\"petit - jean\",\"hallede tlaurent\",\"montoie\",\"calaire\",\"halle de f de\",\"palude\",\"laurant\",\"villards\",\"falle de st laurent\",\"ane de bourg\",\"g chene\",\"no de leurs\",\"pelit chene\",\"cite de vans\",\"st francoise\",\"detienne\",\"martherey .\",\"bis\"]\n",
    "\n",
    "# Filtering out specific values\n",
    "result_df_filtered = result_df[~result_df['Value'].isin(values_to_filter)]\n",
    "\n",
    "#take top 100\n",
    "dictionary = result_df_filtered.sort_values('Count', ascending=False)[0:100]\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "dictionary.to_csv(\"dictionary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ea74c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are at 1832_filtered_numbers.xlsx\n",
      "we are at 1835_corrige_filtered_numbers.xlsx\n",
      "we are at 1836_filtered_numbers.xlsx\n",
      "we are at 1837_filtered_numbers.xlsx\n",
      "we are at 1838_filtered_numbers.xlsx\n",
      "we are at 1839_filtered_numbers.xlsx\n",
      "we are at 1840_filtered_numbers.xlsx\n",
      "we are at 1841_filtered_numbers.xlsx\n",
      "we are at 1842_filtered_numbers.xlsx\n",
      "we are at 1843_filtered_numbers.xlsx\n",
      "we are at 1844_filtered_numbers.xlsx\n",
      "we are at 1845_filtered_numbers.xlsx\n",
      "we are at 1846_filtered_numbers.xlsx\n",
      "we are at 1847_filtered_numbers.xlsx\n",
      "we are at 1848_filtered_numbers.xlsx\n",
      "we are at 1849_filtered_numbers.xlsx\n",
      "we are at 1850_filtered_numbers.xlsx\n",
      "we are at 1851_filtered_numbers.xlsx\n",
      "we are at 1852_filtered_numbers.xlsx\n",
      "we are at 1853_filtered_numbers.xlsx\n",
      "we are at 1854_filtered_numbers.xlsx\n",
      "we are at 1855_corrige_filtered_numbers.xlsx\n",
      "we are at 1855_filtered_numbers.xlsx\n"
     ]
    }
   ],
   "source": [
    "from Levenshtein import distance\n",
    "import difflib\n",
    "\n",
    "# Create an empty DataFrame to store the final result\n",
    "final_result = pd.DataFrame(columns=['nom_rue', 'Suggested_Street_Name', 'Levenshtein_Distance'])\n",
    "\n",
    "# Function to find the closest match from the dictionary\n",
    "def find_closest_match(word, dictionary, levenshtein_weight=0.5, substring_weight=0.5):\n",
    "    min_distance = float('inf')\n",
    "    closest_keyword = None\n",
    "\n",
    "    for keyword in dictionary['Value']:\n",
    "        # Calculate normalized Levenshtein distance\n",
    "        levenshtein_distance = distance(str(word), str(keyword)) / len(keyword)\n",
    "\n",
    "        # Calculate longest matching substring\n",
    "        substring_match = difflib.SequenceMatcher(None, str(word), str(keyword)).find_longest_match(0, len(word), 0, len(keyword))\n",
    "        substring_distance = 1 - substring_match.size / max(len(word), len(keyword))\n",
    "\n",
    "        # Combine the distances with weights\n",
    "        combined_distance = levenshtein_weight * levenshtein_distance + substring_weight * substring_distance\n",
    "\n",
    "        if combined_distance < min_distance:\n",
    "            min_distance = combined_distance\n",
    "            closest_keyword = keyword\n",
    "\n",
    "    return closest_keyword, min_distance\n",
    "\n",
    "# Iterate through each file in the folder and process street names\n",
    "for filename in os.listdir(clean_folder_path):\n",
    "    if filename.endswith(\".xlsx\"):\n",
    "        file_path = os.path.join(clean_folder_path, filename)\n",
    "        df = pd.read_excel(file_path)\n",
    "        print(\"we are at \" + str(filename))\n",
    "\n",
    "        # Add columns for closest dictionary street and Levenshtein distance\n",
    "        df['Suggested_Street_Name'] = ''\n",
    "        df['Levenshtein_Distance'] = 0\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            street_name = row['nom_rue']\n",
    "            if street_name in (\"·\"):\n",
    "                if index > 0:  # Check if it's not the first row\n",
    "                    street_name = df.loc[index - 1, 'nom_rue']\n",
    "                    if street_name in (\"·\"):\n",
    "                        print(\"Problem with dots is here\")\n",
    "                    # Otherwise, you can update the current row in the DataFrame\n",
    "                    else:\n",
    "                        df.loc[index, 'nom_rue'] = street_name\n",
    "                else:\n",
    "                    print(\"Problem with the first row having '·' \")\n",
    "\n",
    "            closest_keyword, min_distance = find_closest_match(street_name, dictionary)\n",
    "            df.at[index, 'Suggested_Street_Name'] = closest_keyword\n",
    "            df.at[index, 'Levenshtein_Distance'] = min_distance\n",
    "\n",
    "        # Append the required columns to the final result\n",
    "        df_temp = df[['nom_rue', 'Suggested_Street_Name', 'Levenshtein_Distance']]\n",
    "        final_result = final_result._append(df_temp, ignore_index=True)\n",
    "\n",
    "# Sort the DataFrame by the 'Levenshtein_Distance' column\n",
    "final_result.sort_values('Levenshtein_Distance', inplace=True)\n",
    "\n",
    "final_result.to_excel(\"distances.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ae2fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"fre\" et \"tre\" deviennent \"barre\" plutot que \"du pre\"\n",
    "final_result.loc[final_result['nom_rue'].isin(['fre', 'tre']), 'Suggested_Street_Name'] = 'du pre'\n",
    "#\"gs jean\" devient \"jean\" plutot que \"grand st jean\"\n",
    "final_result.loc[final_result['nom_rue'] == 'gs jean', 'Suggested_Street_Name'] = 'grand st jean'\n",
    "#\"veuve\" devient \"vennes\" plutot que \"grange veuve\"\n",
    "final_result.loc[final_result['nom_rue'] == 'veuve', 'Suggested_Street_Name'] = 'grange veuve'\n",
    "#\"chaz\" devient \"jean\" plutot que \"etraz\"\n",
    "final_result.loc[final_result['nom_rue'] == 'chaz', 'Suggested_Street_Name'] = 'etraz'\n",
    "#\"pieur\" devient \"palud\" plutot que \"st pierre\"\n",
    "final_result.loc[final_result['nom_rue'] == 'pieur', 'Suggested_Street_Name'] = 'st pierre'\n",
    "#\"rue\" et \"ruc\" devient \"barre\" et \"ouchy\" mais devraient etre effacés\n",
    "final_result = final_result[final_result['nom_rue'] != 'rue']\n",
    "final_result = final_result[final_result['nom_rue'] != 'ruc']\n",
    "# \"boston\" doit etre supprimé car il devrait etre mappé à \"bosson\" pas \"bourg\" mais bosson apparait pas dans le dictionnaire\n",
    "final_result = final_result[final_result['nom_rue'] != 'boston']\n",
    "# \"et\" et \"id id\" doit etre supprimé car il ne peut pas etre mappé a un nom de rue\n",
    "final_result = final_result[final_result['nom_rue'] != 'et']\n",
    "final_result = final_result[final_result['nom_rue'] != 'id id']\n",
    "\n",
    "#\"grand\" devient \"jean\" mais devrait etre effacé\n",
    "final_result = final_result[final_result['nom_rue'] != 'grand']\n",
    "#\"veuf\" devient \"jean\" mais devrait etre \"grange veuve\"\n",
    "final_result.loc[final_result['nom_rue'] == 'veuf', 'Suggested_Street_Name'] = 'grange veuve'\n",
    "\n",
    "#\"francois\" devient \"francs\" plutot que \"st francois\"\n",
    "final_result.loc[final_result['nom_rue'] == 'francois', 'Suggested_Street_Name'] = 'st francois'\n",
    "\n",
    "#\"halle\" devient \"chally\" plutot que \"l halle\"\n",
    "final_result.loc[final_result['nom_rue'] == 'halle', 'Suggested_Street_Name'] = 'l halle'\n",
    "\n",
    "#\"vichy\" devient \"ouchy\" mais devrait etre enlevé (s'il n'apparait pas dans le dictionnaire)\n",
    "\n",
    "final_result.to_excel(\"distances.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5311c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Levenshtein minimum distance row counts\n",
      "Levenshtein_Distance\n",
      "0.000000    33579\n",
      "0.052632        4\n",
      "0.062500       62\n",
      "0.066667       30\n",
      "0.076923      204\n",
      "            ...  \n",
      "1.218182       20\n",
      "1.291399        1\n",
      "1.317391       20\n",
      "1.345652        1\n",
      "1.450000        1\n",
      "Name: count, Length: 837, dtype: int64\n",
      "Number of rows with Levenshtein distance <= 3: 95300\n",
      "Total number of rows: 95300\n",
      "Top 10 suggested keyword values:\n",
      "Suggested_Street_Name\n",
      "martheray               5178\n",
      "bourg                   4702\n",
      "st laurent              4484\n",
      "du pre                  4274\n",
      "grand st jean           4119\n",
      "verdonnet               3542\n",
      "challe de st laurent    3424\n",
      "cite derriere           2805\n",
      "st francois             2675\n",
      "ouchy                   2490\n",
      "Name: count, dtype: int64\n",
      "For the suggested street name 'martheray':\n",
      "Top 3 original street names and their occurrences:\n",
      "1. martheray, 1477\n",
      "2. martherey, 1328\n",
      "3. marteray, 265\n",
      "----\n",
      "For the suggested street name 'bourg':\n",
      "Top 3 original street names and their occurrences:\n",
      "1. bourg, 3630\n",
      "2. de bourg, 789\n",
      "3. bourge, 56\n",
      "----\n",
      "For the suggested street name 'st laurent':\n",
      "Top 3 original street names and their occurrences:\n",
      "1. st laurent, 1401\n",
      "2. laurent, 772\n",
      "3. laurens, 202\n",
      "----\n",
      "For the suggested street name 'du pre':\n",
      "Top 3 original street names and their occurrences:\n",
      "1. du pre, 1881\n",
      "2. pre, 1458\n",
      "3. fre, 244\n",
      "----\n",
      "For the suggested street name 'grand st jean':\n",
      "Top 3 original street names and their occurrences:\n",
      "1. grand st jean, 1072\n",
      "2. st jean, 1032\n",
      "3. grand s jean, 218\n",
      "----\n",
      "For the suggested street name 'verdonnet':\n",
      "Top 3 original street names and their occurrences:\n",
      "1. werdonet, 3290\n",
      "2. verdonnet, 66\n",
      "3. bourdonnette, 43\n",
      "----\n",
      "For the suggested street name 'challe de st laurent':\n",
      "Top 3 original street names and their occurrences:\n",
      "1. annee de naissance, 379\n",
      "2. challe de st laurent, 174\n",
      "3. hallede st laurent, 119\n",
      "----\n",
      "For the suggested street name 'cite derriere':\n",
      "Top 3 original street names and their occurrences:\n",
      "1. cite derriere, 404\n",
      "2. derriere, 209\n",
      "3. cile derriere, 155\n",
      "----\n",
      "For the suggested street name 'st francois':\n",
      "Top 3 original street names and their occurrences:\n",
      "1. st francois, 1076\n",
      "2. francois, 707\n",
      "3. jn francois, 234\n",
      "----\n",
      "For the suggested street name 'ouchy':\n",
      "Top 3 original street names and their occurrences:\n",
      "1. ouchy, 2175\n",
      "2. cuchy, 87\n",
      "3. luchy, 50\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Print statistics of the number of rows per Levenshtein distance\n",
    "statistics = final_result['Levenshtein_Distance'].value_counts().sort_index()\n",
    "print(\"Top 10 Levenshtein minimum distance row counts\")\n",
    "print(statistics[0:10])\n",
    "\n",
    "# Calculate and print the number of rows with Levenshtein distance <= 3\n",
    "num_rows_levenshtein_3 = sum(final_result['Levenshtein_Distance'] <= 3)\n",
    "print(\"Number of rows with Levenshtein distance <= 3:\", num_rows_levenshtein_3)\n",
    "\n",
    "# Calculate and print the total number of rows\n",
    "total_rows = len(final_result)\n",
    "print(\"Total number of rows:\", total_rows)\n",
    "\n",
    "# Print statistics of the values and occurrences of each suggested keyword\n",
    "keyword_statistics = final_result['Suggested_Street_Name'].value_counts()\n",
    "\n",
    "print(\"Top 10 suggested keyword values:\")\n",
    "print(keyword_statistics[0:10])\n",
    "\n",
    "# Find the top 10 suggested street names\n",
    "top_suggested_street_names = final_result['Suggested_Street_Name'].value_counts().head(10).index.tolist()\n",
    "\n",
    "# Create a dictionary to store the top 10 original street names for each suggested street name\n",
    "top_original_street_names = {}\n",
    "\n",
    "# Iterate through each of the top 10 suggested street names\n",
    "for suggested_street_name in top_suggested_street_names:\n",
    "    filtered_data = final_result[final_result['Suggested_Street_Name'] == suggested_street_name]\n",
    "    original_street_counts = filtered_data['nom_rue'].value_counts()\n",
    "    top_original_streets = list(original_street_counts.head(3).items())\n",
    "    top_original_street_names[suggested_street_name] = top_original_streets\n",
    "\n",
    "# Print the results\n",
    "for suggested_street_name, top_original_streets in top_original_street_names.items():\n",
    "    print(f\"For the suggested street name '{suggested_street_name}':\")\n",
    "    print(\"Top 3 original street names and their occurrences:\")\n",
    "    for i, (original_street, occurrences) in enumerate(top_original_streets, start=1):\n",
    "        print(f\"{i}. {original_street}, {occurrences}\")\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ef0ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all files in recensements_cleaned, append Suggested_Street_Name value given the current nom_rue value and the distances.csv mapping if the distance value in distances.csv is <= 3\n",
    "\n",
    "# Reading the 'final_result' dataframe and dropping duplicates\n",
    "unique_distances = final_result.drop_duplicates(subset='nom_rue', keep='first')\n",
    "\n",
    "clean_folder_path = './recensements_cleaned'\n",
    "\n",
    "# Iterate through each file in the folder and process street names\n",
    "for filename in os.listdir(clean_folder_path):\n",
    "    if filename.endswith(\".xlsx\"):\n",
    "        file_path = os.path.join(clean_folder_path, filename)\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        # Merge the 'df' dataframe with 'unique_distances' based on the 'nom_rue' column\n",
    "        merged_df = pd.merge(df, unique_distances, on='nom_rue', how='left')\n",
    "        \n",
    "        # Keep only the rows where the 'Levenshtein_Distance' column value is <= 3\n",
    "        merged_df = merged_df[merged_df['Levenshtein_Distance'] <= 3]\n",
    "        \n",
    "        # Save the resulting Excel file\n",
    "        output_file = file_path.replace('.xlsx', '_merged.xlsx')\n",
    "        output_file = output_file.replace('./recensements_cleaned', './recensements_merged')\n",
    "        merged_df.to_excel(output_file, index=False)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40425b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Levenshtein import distance\n",
    "\n",
    "recensements_merged_path = './recensements_merged'\n",
    "\n",
    "# Use list comprehension for file reading\n",
    "file_names = [filename for filename in os.listdir(recensements_merged_path) if filename.endswith(\".xlsx\") and not filename.startswith(\"~$\")]\n",
    "dataframes = [pd.read_excel(os.path.join(recensements_merged_path, filename)) for filename in file_names]\n",
    "\n",
    "# Define the columns for comparison\n",
    "comparison_columns = ['proprietaire_nom', 'chef_prenom', 'chef_nom', 'chef_annee_naissance', 'epouse_nom', 'epouse_annee_naissance', 'enfants_dans_la_commune_prenom', 'enfants_annee_naissance', 'chef_origine', 'chef_vocation']\n",
    "\n",
    "# Function for distance calculation\n",
    "def calculate_distance(row1, row2):\n",
    "    return np.sum([distance(str(row1[col]), str(row2[col])) for col in comparison_columns])\n",
    "\n",
    "# Function for matching\n",
    "def match_rows(args):\n",
    "    index, row, file_to_match = args\n",
    "    min_distance = float('inf')\n",
    "    min_row = None\n",
    "    for matching_index, matching_row in file_to_match.iterrows():\n",
    "        distance_sum = calculate_distance(row, matching_row)\n",
    "        if distance_sum < min_distance:\n",
    "            min_distance = distance_sum\n",
    "            min_row = matching_row\n",
    "    return min_row, min_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18319ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start matching\n",
      "0\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "def match_rows_vectorized(row, file_to_match):\n",
    "    distances = file_to_match.apply(lambda matching_row: calculate_distance(row, matching_row), axis=1)\n",
    "    min_distance_index = distances.idxmin()\n",
    "    min_row = file_to_match.loc[min_distance_index]\n",
    "    return min_row, distances[min_distance_index]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "matches = []\n",
    "\n",
    "print(\"start matching\")\n",
    "\n",
    "# Iterate over rows of the first dataframe\n",
    "for index, row in dataframes[0].iterrows():\n",
    "    current_match = [row]  # the first list element is just the row we want to match\n",
    "    total_match_distance = 0\n",
    "    \n",
    "    if(index%10==0):\n",
    "        print(index)\n",
    "    \n",
    "    # Use vectorized operations to match rows with other dataframes\n",
    "    for file_to_match in dataframes[1:]:\n",
    "        result, file_match_distance = match_rows_vectorized(row, file_to_match)\n",
    "        current_match.append(result)\n",
    "        total_match_distance += file_match_distance\n",
    "    \n",
    "    row_matching_and_distance = [current_match, total_match_distance]\n",
    "    matches.append(row_matching_and_distance)\n",
    "\n",
    "print(\"finished matching\")\n",
    "\n",
    "# Sort matches based on total_match_distance\n",
    "matches.sort(key=lambda x: x[1])\n",
    "\n",
    "# Print the top 10 rows with the best matches\n",
    "top_matches = matches[:10]\n",
    "for index, match_group in enumerate(top_matches):\n",
    "    print(f\"Row {index} has matches in the following files:\")\n",
    "    for i, match_row in enumerate(match_group[0]):\n",
    "        print(f\"   {file_names[i]}: {match_row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807198a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
